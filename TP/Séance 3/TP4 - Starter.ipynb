{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15419443",
   "metadata": {},
   "source": [
    "# TP4 - Agents\n",
    "\n",
    "Dans ce notebook on s'intéresse à la méthodologie agent en utilisant le framework technique LangChain. Notre application sera l'api de la World Bank Data qui est une source de données à l'échelle mondiale sur l'état, d'un point de vue statistique, d'un pays.\n",
    "La difficulté de cette API est qu'elle est très riche, avec des indicateurs ayant des codes complexes. De plus, les codes des pays sont spécifiques, la manière de requêter est précise.\n",
    "\n",
    "Pour exploiter du mieux possible les données disponibles, on se propose de définir un agent dont le rôle est de traiter une questions posées en langage naturel et requêter puis analyser les résultats.\n",
    "\n",
    "## Trouver le bon indicateur\n",
    "\n",
    "On commence par le premier enjeu : traduire une question en une liste d'indicateurs potentiel permettant d'aider à répondre. Pour ce faire, nous avons récupérer l'ensemble des indicateurs disponible et la descriptions associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_embedding_text(row: pd.Series) -> str:\n",
    "    answer = f\"\"\"Indicator code: {row['indicator']}\\nIndicator description: {row['description']}\\nIndicator source name: {row['source_name']}\"\"\"\n",
    "    return answer\n",
    "\n",
    "df_indicators = pd.read_csv('WBData_indicators.csv')\n",
    "\n",
    "df_indicators[\"embedding_text\"] = df_indicators.apply(build_embedding_text, axis=1)\n",
    "df_indicators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabba49",
   "metadata": {},
   "source": [
    "Nous allons construire un embedding de la colonne *embedding_text* pour pouvoir dans un second temps la requêter avec la méthoode FAISS.\n",
    "\n",
    "**Consigne** : En exploitant les fonctions `build_faiss_index` et `retrieve_index` dans le module `rag_utils`, constuire l'embedding et le tester sur question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e08d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206c6280",
   "metadata": {},
   "source": [
    "Il faut maintenant constuire une fonction pour que ça soit un outil de notre agent.\n",
    "\n",
    "**Consigne** : Construire une fonction `retrieve_indicators` qui à partir d'une question et d'un nombre d'indicateurs à renvoyer, renvoie les indicateurs les plus pertinents (selon l'embedding) pour la question.\n",
    "Dans un soucis de simplicité, on ne renverras que trois colonnes : l'indicateur, sa description et le score associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583967a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7bcbb11",
   "metadata": {},
   "source": [
    "Nous sommes maintenant capables d'identifier des indicateurs pertinent pour une question donnée. Il faut maintenant obtenir les codes des pays qui nous intéresse.\n",
    "\n",
    "## Identifier les codes de pays\n",
    "\n",
    "De la même manière que précédemment, nous avons l'ensemble des valeurs disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"WBData_countries.csv\")\n",
    "countries[\"embedding_text\"] = countries.apply(lambda row: f\"\"\"Code: {row[\"Code\"]}\\nDescription: {row[\"Description\"]}\"\"\", axis=1)\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db235f9f",
   "metadata": {},
   "source": [
    "**Consigne** : reproduire *mutatis mutandis* le travail précédent dans le cadre des codes de pays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c64a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd7f259e",
   "metadata": {},
   "source": [
    "A présent nous avons deux fonctions : une pour indentifier les indicateurs pertinent, une pour identifier les codes pays d'intérêts.\n",
    "\n",
    "## Appeler correctement l'API\n",
    "\n",
    "L'objectif est à présent de requêter l'API correctement. Par exemple pour l'inflation annuelle en pourcentage, vue par le consommateur, en France entre 2015 et 2020, la requête est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbdata\n",
    "\n",
    "code = \"FP.CPI.TOTL.ZG\"\n",
    "country = \"FRA\"\n",
    "series = wbdata.get_series(code, date=(\"2015\", \"2020\"), country=[country])\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0f02",
   "metadata": {},
   "source": [
    "Si on souhaite l'obtenir pour la France et l'Allemagne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"FP.CPI.TOTL.ZG\"\n",
    "country = [\"FRA\", \"DEU\"]\n",
    "series = wbdata.get_series(code, date=(\"2015\", \"2020\"), country=country)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427b5a0",
   "metadata": {},
   "source": [
    "**Consigne** : Compléter la fonction `query_api` dont l'objectif est de requêter l'API World Bank Data. A partir d'un code d'indicateur, d'une période en années et d'un code de pays, retourner un DataFrame simple de lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a089ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a5aaeea",
   "metadata": {},
   "source": [
    "## Agent ! \n",
    "\n",
    "Passons maintenant à l'étape de conception de l'agent, nous utiliserons LangGraph pour le faire.\n",
    "\n",
    "Pour commencer, faisons le récapitulatif des fonctions que nous avons construites :\n",
    "1. `retrieve_indicators` : récupérer les codes pertinents pour une question donnée\n",
    "2. `retrieve_countries` : récupérer les codes pays pertinents pour une question donnée\n",
    "3. `query_api` : requêter proprement l'API d'intérêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_REGISTRY = {\n",
    "    \"retrieve_indicators\": retrieve_indicators,\n",
    "    \"retrieve_countries\": retrieve_countries,\n",
    "    \"query_api\": query_api\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49459ab3",
   "metadata": {},
   "source": [
    "### Structure de l'agent\n",
    "\n",
    "Dans LangGraph, un agent est un graphe d'actions et d'informations évolutifs. Nous allons définir :\n",
    "1. Une **classe** qui représentera l'agent. L'objectif est de pouvoir stocker et utiliser par la suite à bon essient les avancées de l'agent.\n",
    "2. Des **méthodes** qui sont les sommets dans le graphes d'actions de l'agent. Ces méthodes exploitent les informations contenues dans la classe.\n",
    "3. Un **graphe** qui va permettre de définir comment passer d'un sommet à l'autre.\n",
    "\n",
    "Commençons par la classe. Nous appelons l'agent à partir d'une **question** sur laquelle il va **réfléchir** et élaborer un plan d'action qui ici se résumé à des **appels** aux fonctions que nous avons définies. Puis, exploitant les **résultats** de ces appels, l'agent pourra **requêter** l'API puis **analyser** le résultat, à la lumière de la question posée initialement.\n",
    "\n",
    "Nous allons exactement coder cela, chaque mot en gras correspond à une information que l'on va stocker et exploiter au moment opportun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08461b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    tool_thoughts: str\n",
    "    query_thoughts: str\n",
    "    tool_calls: List[dict]\n",
    "    tool_results: List[Any]\n",
    "    query_calls: List[dict]\n",
    "    query_results: List[dict]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6040ac",
   "metadata": {},
   "source": [
    "Pour travailler, nous n'utiliserons qu'un seul modèle, ici Gemma3 version 12B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb591c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:12b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fd5fe",
   "metadata": {},
   "source": [
    "### Préparation de l'appel\n",
    "\n",
    "La première étape consiste à préparer l'appel à l'API. Nous avons besoin que le modèle puisse à la fois nous liver sa réflexion et les outils qu'il souhaite exploiter.\n",
    "Nous allons donc définir notre propre *parser* du résultat du modèle :\n",
    "\n",
    "1. **Raisonnement** : pour auditer la réflexion du modèle. Ici, simplement du texte suffit.\n",
    "2. **Outil** : pour savoir quels outils appeler avec quel paramètrage. Ici nous devons définir une liste d'appels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081174ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    name: str = Field(description=\"Name of the tool to call\")\n",
    "    args: Dict[str, Any] = Field(description=\"Arguments for the tool\")\n",
    "\n",
    "class ReasoningOutput(BaseModel):\n",
    "    thought: str = Field(description=\"Short explanation of reasoning\")\n",
    "    tools: List[ToolCall] = Field(description=\"Tools to call\")\n",
    "\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ReasoningOutput)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b951b",
   "metadata": {},
   "source": [
    "Nous avons en plus les instructions à fournir au modèle pour formatter la réponse.\n",
    "\n",
    "Nous pouvons enfin créer notre premier sommet/noeud du graphe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "You are a AI agent data analyst using the World Bank Data API to answer the user question. You MUST use the two tools to answer the question.\n",
    "\n",
    "User question:\n",
    "{state['question']}\n",
    "\n",
    "Available tools:\n",
    "- retrieve_indicators(query: str) : ask a question to see which indicators might help\n",
    "- retrieve_countries(query: str) : ask a question to retrieve the code of a specific country or a geographic zone\n",
    "\n",
    "\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt)\n",
    "    decision = parser.parse(response)\n",
    "    \n",
    "    state[\"tool_thoughts\"] = decision.thought\n",
    "    state[\"tool_calls\"] = [\n",
    "        {\"name\": tool.name, \"args\": tool.args} for tool in decision.tools\n",
    "    ]\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e51f0",
   "metadata": {},
   "source": [
    "Nous avons appelé le modèle, récupérer sa réponse dans un format facilement exploitable pour nous puis stocké les informations. Il nous faut maintenant concrétement appeler les outils et stocker les résultats : c'est complétement déterministe.\n",
    "\n",
    "### Appels d'outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48939e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_execution_node(state: AgentState) -> AgentState:\n",
    "    results = []\n",
    "    for call in state[\"tool_calls\"]:\n",
    "        tool_name = call[\"name\"]\n",
    "        tool_args = call.get(\"args\", {})\n",
    "\n",
    "        tool_function = TOOL_REGISTRY.get(tool_name)\n",
    "        if tool_function is None:\n",
    "            results.append({\"tool\": tool_name, \"args\": tool_args, \"error\": \"Unknown tool\"})\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = tool_function(**tool_args)\n",
    "            results.append({\"tool\": tool_name, \"args\": tool_args, \"result\": result})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    state[\"tool_results\"] = results\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b4ebe",
   "metadata": {},
   "source": [
    "### Noeuds de requête\n",
    "\n",
    "Après la préparation et la récupération des informations via les outils que nous avons défini plus tôt, nous pouvons définir un nouveau sommet/noeud dont l'objectif est de définir l'appel à la fonction `query_api`.\n",
    "\n",
    "**Consigne** En s'inspirant du sommet `preparation_node`, compléter la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36935e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "You are in a AI agent system. Based on the following informations, use the tool to help answer the user question.\n",
    "\n",
    "User question:\n",
    "{state['question']}\n",
    "\n",
    "Your reasoning:\n",
    "{state['tool_thoughts']}\n",
    "\n",
    "Data retrieved from tools:\n",
    "{state['tool_results']}\n",
    "\n",
    "Available tool: query_api(code, date, country) with parameters :\n",
    "    - code : string linked to an indicator in the world bank data. Example : FR.INR.MMKT\n",
    "    - date : string of the year. If you need to query for a period, use a list with the starting and ending year. Examples : \"2025\" or [\"2020\", \"2023\"]\n",
    "    - country: string or list of string representing a country with a 3 letter code. Examples : \"FRA\" or [\"UAE\", \"DEU\"]\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "    ...\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170b4f0",
   "metadata": {},
   "source": [
    "Il reste à exécuter ce que ce sommet/noeud a jugé utile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_execution_node(state: AgentState) -> AgentState:\n",
    "    results = []\n",
    "    for call in state[\"query_calls\"]:\n",
    "        tool_name = call[\"name\"]\n",
    "        tool_args = call.get(\"args\", {})\n",
    "\n",
    "        tool_function = TOOL_REGISTRY.get(tool_name)\n",
    "        if tool_function is None:\n",
    "            results.append({\"tool\": tool_name, \"args\": tool_args, \"error\": \"Unknown tool\"})\n",
    "            continue\n",
    "\n",
    "        result = tool_function(**tool_args)\n",
    "        results.append({\"tool\": tool_name, \"args\": tool_args, \"result\": result})\n",
    "\n",
    "    state[\"query_results\"] = results\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986bba8",
   "metadata": {},
   "source": [
    "### Synthèse\n",
    "\n",
    "Après tout ces appels et ces informations collectées, il est temps de les restituer sous forme de simple texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c751849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in data analysis and you used the World Bank Data API.\n",
    "\n",
    "User question:\n",
    "{state['question']}\n",
    "\n",
    "Your reasoning:\n",
    "{state['query_thoughts']}\n",
    "\n",
    "Data retrieved from tools:\n",
    "{state['query_results']}\n",
    "\n",
    "Write a concise and clear answer to the user question, based ONLY on the information you have. Be thoughtful, write in plain text : do not use too much formatting.\n",
    "\"\"\"\n",
    "    state[\"answer\"] = model.invoke(prompt)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cfb361",
   "metadata": {},
   "source": [
    "### Définition du graphe\n",
    "\n",
    "A ce stade, nous avons des bouts du puzzles mais ils ne sont pas assemblé. C'est ce que nous allons faire maintenant. On commence par ajouter les noeuds/sommets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"preparation\", preparation_node)\n",
    "graph.add_node(\"preparation_tools\", tool_execution_node)\n",
    "\n",
    "graph.add_node(\"query\", query_node)\n",
    "graph.add_node(\"query_tools\", query_execution_node)\n",
    "\n",
    "graph.add_node(\"synthesis\", synthesis_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80eb961",
   "metadata": {},
   "source": [
    "Puis les liens entres les différents noeuds/sommets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_entry_point(\"preparation\")\n",
    "graph.add_edge(\"preparation\", \"preparation_tools\")\n",
    "graph.add_edge(\"preparation_tools\", \"query\")\n",
    "graph.add_edge(\"query\", \"query_tools\")\n",
    "graph.add_edge(\"query_tools\", \"synthesis\")\n",
    "\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f33d4a",
   "metadata": {},
   "source": [
    "Il est maintenant temps de l'utiliser !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What the evolution of France's inflation between 2015 and 2025 ? Comment on this value using the inflation in Europe, or in Germany for example.\"\n",
    "\n",
    "initial_state = {\n",
    "    \"question\": question,\n",
    "    \"tool_thoughts\": \"\",\n",
    "    \"query_thoughts\": \"\",\n",
    "    \"tool_calls\": [],\n",
    "    \"tool_results\": [],\n",
    "    \"query_calls\": [],\n",
    "    \"query_results\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "\n",
    "result = agent.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e91b0d",
   "metadata": {},
   "source": [
    "On peut obtenir le résultat de l'agent ainsi que ces différentes réflexion tout au long du processus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8baa7",
   "metadata": {},
   "source": [
    "C'est pas mal ! Mais nous avons probablement eu de la chance : la requête a été bien formulée. Ce ne sera peut-être pas toujours le cas, nous avons besoin de plus de sécurité.\n",
    "\n",
    "## Plus de robustesse dans la génération de la requête\n",
    "\n",
    "On se propose ici d'améliorer cet aspect en modifiant le graphe :\n",
    "- Ajout d'un module de **validation déterministe** des paramètres de la requête sélectionné\n",
    "- Ajout d'un noeud/sommet de revus des paramètres s'il y a une erreur, pour le **réparer**\n",
    "\n",
    "Ces deux ajustements nous demanderons de modifier la classe de définition de l'agent et le graphe.\n",
    "\n",
    "### Validation déterministe\n",
    "\n",
    "On commence par la classe `QueryPlan` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPlan(BaseModel):\n",
    "    indicator_code: str = Field(description=\"World Bank indicator code\")\n",
    "    countries: List[str] = Field(description=\"List of 3-letter country codes\")\n",
    "    start_year: int = Field(description=\"Start year of the query\")\n",
    "    end_year: int = Field(description=\"End year of the query\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ddb56",
   "metadata": {},
   "source": [
    "**Consigne** : Modifier la classe de l'agent pour remplacer *query_calls* et *query_results* par :\n",
    "* *query_plan* qui sera un dictionnaire optionnel\n",
    "* *validation_errors* qui sera une liste de string optionnel, pour aider à débugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8ca29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ba9a56",
   "metadata": {},
   "source": [
    "Il nous faut modifier la fonction `query_node` pour produire quelque chose de plus simple à valider :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "query_plan_parser = PydanticOutputParser(pydantic_object=QueryPlan)\n",
    "query_plan_format = query_plan_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "def query_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "You are an AI agent building a structured query plan for the World Bank Data API.\n",
    "\n",
    "User question:\n",
    "{state['question']}\n",
    "\n",
    "Retrieved indicators and countries:\n",
    "{state['tool_results']}\n",
    "\n",
    "Return exactly one query plan with:\n",
    "- indicator_code\n",
    "- countries (list)\n",
    "- start_year\n",
    "- end_year\n",
    "\n",
    "{query_plan_format}\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt)\n",
    "    plan = query_plan_parser.parse(response)\n",
    "\n",
    "    state[\"query_thoughts\"] = \"Structured query plan generated\"\n",
    "    state[\"query_plan\"] = plan.model_dump()\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c2df8",
   "metadata": {},
   "source": [
    "Puis il nous faut un module de validation déterministe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_INDICATORS = set(df_indicators[\"indicator\"].values)\n",
    "VALID_COUNTRIES = set(countries[\"Code\"].values)\n",
    "MIN_YEAR = 1960\n",
    "MAX_YEAR = 2025\n",
    "\n",
    "\n",
    "def validation_node(state: AgentState) -> AgentState:\n",
    "    plan = state.get(\"query_plan\")\n",
    "    errors = []\n",
    "\n",
    "    if plan is None:\n",
    "        errors.append(\"No query plan found.\")\n",
    "        state[\"validation_errors\"] = errors\n",
    "        return state\n",
    "\n",
    "    if plan[\"indicator_code\"] not in VALID_INDICATORS:\n",
    "        errors.append(f\"Invalid indicator code: {plan['indicator_code']}\")\n",
    "\n",
    "    for c in plan[\"countries\"]:\n",
    "        if c not in VALID_COUNTRIES:\n",
    "            errors.append(f\"Invalid country code: {c}\")\n",
    "\n",
    "    if not (MIN_YEAR <= plan[\"start_year\"] <= MAX_YEAR):\n",
    "        errors.append(f\"start_year out of bounds: {plan['start_year']}\")\n",
    "\n",
    "    if not (MIN_YEAR <= plan[\"end_year\"] <= MAX_YEAR):\n",
    "        errors.append(f\"end_year out of bounds: {plan['end_year']}\")\n",
    "\n",
    "    state[\"validation_errors\"] = errors if errors else None\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063ee6c",
   "metadata": {},
   "source": [
    "Il nous faut également, un noeud pour éventuellement ajuster le plan d'appel s'il ne vérifie pas la validation.\n",
    "\n",
    "**Consigne** : Compléter la fonction ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_node(state: AgentState) -> AgentState:\n",
    "    prompt = f\"\"\"\n",
    "The following query plan is invalid:\n",
    "\n",
    "{state['query_plan']}\n",
    "\n",
    "Errors:\n",
    "{state['validation_errors']}\n",
    "\n",
    "Fix the query plan so that:\n",
    "- The indicator exists\n",
    "- Country codes are valid\n",
    "- Years are within bounds\n",
    "\n",
    "Return a corrected query plan only.\n",
    "\n",
    "{query_plan_format}\n",
    "\"\"\"\n",
    "    response = ...\n",
    "    plan = ...\n",
    "    state[\"query_plan\"] = plan.model_dump()\n",
    "    state[\"validation_errors\"] = None\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0653b30",
   "metadata": {},
   "source": [
    "La fonction `query_execution_node` peut être largement simplifiée maintenant que nous avons fait tout ces changements.\n",
    "\n",
    "**Consigne** : Re-définir la fonction `query_execution_node` en prenant en compte le plan stocké dans la mémoire de l'agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d888ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc0e490",
   "metadata": {},
   "source": [
    "Finalement, nous pouvons ré-écrire le graphe en y ajoutant nos nouveaux sommets et surtout introduire des noeuds optionnels !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"preparation\", preparation_node)\n",
    "graph.add_node(\"preparation_tools\", tool_execution_node)\n",
    "graph.add_node(\"query\", query_node)\n",
    "graph.add_node(\"validate\", validation_node)\n",
    "graph.add_node(\"repair\", repair_node)\n",
    "graph.add_node(\"query_tools\", query_execution_node)\n",
    "graph.add_node(\"synthesis\", synthesis_node)\n",
    "\n",
    "graph.set_entry_point(\"preparation\")\n",
    "graph.add_edge(\"preparation\", \"preparation_tools\")\n",
    "graph.add_edge(\"preparation_tools\", \"query\")\n",
    "graph.add_edge(\"query\", \"validate\")\n",
    "\n",
    "def validation_router(state: AgentState):\n",
    "    if state.get(\"validation_errors\"):\n",
    "        return \"repair\"\n",
    "    return \"query_tools\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"validate\",\n",
    "    validation_router,\n",
    "    {\n",
    "        \"repair\": \"repair\",\n",
    "        \"query_tools\": \"query_tools\",\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"repair\", \"validate\")\n",
    "graph.add_edge(\"query_tools\", \"synthesis\")\n",
    "\n",
    "agent = graph.compile()\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8786d9",
   "metadata": {},
   "source": [
    "C'est une structure plus complexe ! Et a priori plus robuste sur l'appel à l'API. Mais puisque l'agent met du temps à répondre, nous souhaiterions être certain qu'il est parti sur la bonne piste.\n",
    "\n",
    "## *Human in the loop*\n",
    "\n",
    "Il est temps d'intégrer l'humain dans le processus pour valider ou non que le plan identifié est correct. Si ce n'est pas le cas, alors l'humain peut modifier le pla voire préciser sa question.\n",
    "\n",
    "Pour démarrer, nous devons à nouveau modifier la classe de l'agent.\n",
    "\n",
    "**Consigne** : Ajouter un dictionnaire optionnel nommé *human_feedback*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee8fb70",
   "metadata": {},
   "source": [
    "On continue avec le noeud concernant l'appel à l'humain. On se propose trois possibilitées :\n",
    "1. **Approuver** : on continue avec ce plan\n",
    "2. **Editer** : on modifie le plan qui est proposé par l'agent, puis on repart sur le module de validation\n",
    "3. **Rejeter** : on reformule la question que l'on a posé, puis on repart sur l'étape de préparation\n",
    "\n",
    "Pour éviter le cas où l'on édite le plan, qu'il est valider par le module de validation et qu'on nous re-sollicite, on ajoute une vérification que l'humain n'a pas déjà été sollicité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_approval_node(state: AgentState) -> AgentState:\n",
    "    if state.get(\"human_feedback\"):\n",
    "        return state\n",
    "    else:\n",
    "        plan = state[\"query_plan\"]\n",
    "\n",
    "        print(\"\\nProposed query plan:\")\n",
    "        print(f\"Indicator: {plan['indicator_code']}\")\n",
    "        print(f\"Countries: {', '.join(plan['countries'])}\")\n",
    "        print(f\"Years: {plan['start_year']}–{plan['end_year']}\")\n",
    "\n",
    "        decision = input(\"\\nApprove? (y = yes / e = edit / n = reject): \").strip().lower()\n",
    "\n",
    "        if decision == \"y\":\n",
    "            state[\"human_feedback\"] = {\"approved\": True}\n",
    "\n",
    "        elif decision == \"e\":\n",
    "            edited = input(\"\\nEnter corrected query plan as JSON:\\n\")\n",
    "            state[\"human_feedback\"] = {\"approved\": False, \"edited_plan\": edited}\n",
    "\n",
    "        else:\n",
    "            new_q = input(\"\\nPlease rephrase your question:\\n\")\n",
    "            state[\"human_feedback\"] = {\"approved\": False, \"new_question\": new_q}\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbce56",
   "metadata": {},
   "source": [
    "Et on obtient alors un nouveau graphe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"preparation\", preparation_node)\n",
    "graph.add_node(\"preparation_tools\", tool_execution_node)\n",
    "graph.add_node(\"query\", query_node)\n",
    "graph.add_node(\"validate\", validation_node)\n",
    "graph.add_node(\"repair\", repair_node)\n",
    "\n",
    "graph.add_node(\"human_approval\", human_approval_node)\n",
    "\n",
    "graph.add_node(\"query_tools\", query_execution_node)\n",
    "graph.add_node(\"synthesis\", synthesis_node)\n",
    "\n",
    "graph.set_entry_point(\"preparation\")\n",
    "graph.add_edge(\"preparation\", \"preparation_tools\")\n",
    "graph.add_edge(\"preparation_tools\", \"query\")\n",
    "graph.add_edge(\"query\", \"validate\")\n",
    "\n",
    "def validation_router(state: AgentState):\n",
    "    return \"repair\" if state.get(\"validation_errors\") else \"human_approval\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"validate\",\n",
    "    validation_router,\n",
    "    {\n",
    "        \"repair\": \"repair\",\n",
    "        \"human_approval\": \"human_approval\",\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"repair\", \"validate\")\n",
    "\n",
    "def approval_router(state: AgentState):\n",
    "    fb = state[\"human_feedback\"]\n",
    "\n",
    "    if fb.get(\"approved\"):\n",
    "        return \"query_tools\"\n",
    "    elif \"edited_plan\" in fb:\n",
    "        return \"validate\"\n",
    "    elif \"new_question\" in fb:\n",
    "        return \"preparation\"\n",
    "    else:\n",
    "        return \"preparation\"\n",
    "\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"human_approval\",\n",
    "    approval_router,\n",
    "    {\n",
    "        \"query_tools\": \"query_tools\",\n",
    "        \"validate\": \"validate\",\n",
    "        \"preparation\": \"preparation\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"query_tools\", \"synthesis\")\n",
    "\n",
    "agent = graph.compile()\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb38954",
   "metadata": {},
   "source": [
    "Testons-le !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e64782",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What the evolution of France's inflation between 2015 and 2025 ? Comment on this value using the inflation in Europe, or in Germany for example.\"\n",
    "\n",
    "initial_state = {\n",
    "    \"question\": question,\n",
    "\n",
    "    \"tool_thoughts\": \"\",\n",
    "    \"tool_calls\": [],\n",
    "    \"tool_results\": [],\n",
    "\n",
    "    \"query_thoughts\": \"\",\n",
    "    \"query_plan\": {},\n",
    "    \"validation_errors\": [],\n",
    "\n",
    "    \"human_feedback\": {},\n",
    "\n",
    "    \"query_results\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "\n",
    "result = agent.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
