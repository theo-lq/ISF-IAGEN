{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b68162",
   "metadata": {},
   "source": [
    "# TP3 - Fine tuning\n",
    "\n",
    "L'objectif de ce TP est de présenter comment exploiter les modèles disponibles sur HuggingFace, plus particulièrement pour des tâches de classification. Nous mettrons également en pratique l'approche [*Two-stage fine-tuning*](https://arxiv.org/pdf/2207.10858).\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Les flux RSS, de l'anglais *Rich Site Summary*, est un flux d'information pour partager simplement des informations. Largement utilisé dans le domaine de la communication par les médias, nous pouvons nous tenir au courant des informations que les journaux partagent par exemple.\n",
    "Cependant, le volume d'informations peut être rapidement très important pour pouvoir être lu. On se propose de construire un filtre pour nous notifier uniquement quand une information sera jugée *d'intérêt*.\n",
    "\n",
    "Pour cela, nous avons sauvegardé puis labellisé les flux RSS de plusieurs journaux mondiaux en anglais, pendant plusieurs semaines. Importons et visualisons la bases de données à disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"Complete.csv\")\n",
    "\n",
    "df[\"published\"] = pd.to_datetime(df[\"published\"])\n",
    "df = df.loc[~df[\"target\"].isna()].copy()\n",
    "df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "\n",
    "imbalanced_rate = df[\"target\"].mean()\n",
    "print(f\"{df.shape[0]} news with {100 * imbalanced_rate:.2f}% of positive class\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19931804",
   "metadata": {},
   "source": [
    "## Préparation\n",
    "\n",
    "Nous n'allons exploiter que le titre et le contenu du flux RSS, et avant de commencer nous allons nettoyer un peu le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45710a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(title: str, summary: str) -> str:\n",
    "    \n",
    "    def clean_string(string):\n",
    "        #string = string.lower()\n",
    "        string = string.replace(\"(Source: Bloomberg)\", \"\")\n",
    "        string = string.replace(\"“\", \"'\")\n",
    "        string = string.replace(\"”\", \"'\")\n",
    "        string = string.replace(\"\\n\", \"\")\n",
    "        string = string.replace(\"  \", \" \")\n",
    "        return string.strip()\n",
    "\n",
    "    title = clean_string(title)\n",
    "    summary = clean_string(summary)\n",
    "\n",
    "    return f\"Title: {title}\\nSummary: {summary}\"\n",
    "\n",
    "\n",
    "df[\"text\"] = df.apply(lambda row: clean_text(row[\"title\"], row[\"summary\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c2960",
   "metadata": {},
   "source": [
    "Puisque le dataset est dépendant du temps, nous allons le découper en jeu d'entraînement et de validation en suivant cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024281d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.sort_values(\"published\")\n",
    "split_date = df[\"published\"].quantile(train_ratio)\n",
    "\n",
    "df_train = df[df[\"published\"] <= split_date][[\"text\", \"target\"]]\n",
    "df_val   = df[df[\"published\"] >  split_date][[\"text\", \"target\"]]\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "print(f\"Training size:   {len(df_train)}, imbalanced rate: {100*df_train.target.mean():.2f}%\")\n",
    "print(f\"Validation size: {len(df_val)}, imbalanced rate: {100*df_val.target.mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d353f",
   "metadata": {},
   "source": [
    "Puisque nous avons un déséquilibre, nous allons le reporter dans la fonction de perte. Pour préparer cette étape, nous allons utiliser la fonction [`compute_class_weight`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) et stocker son résultat dans un [`Tensor`](https://docs.pytorch.org/docs/stable/tensors.html) de PyTorch pour l'exploiter dans la fonction de perte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "labels = df_train[\"target\"].values\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0, 1]),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093593f",
   "metadata": {},
   "source": [
    "## Premier entraînement\n",
    "\n",
    "Il est maintenant temps de basculer du monde classique numpy, pandas, scikit-learn à celui de la librairies transformers d'HuggingFace.\n",
    "\n",
    "### Dataset d'entraînement\n",
    "\n",
    "On ne travaille plus avec des DataFrames pandas mais des [Datasets](https://huggingface.co/docs/datasets/use_with_pandas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val   = Dataset.from_pandas(df_val)\n",
    "\n",
    "ds_train = ds_train.rename_column(\"target\", \"labels\")\n",
    "ds_val   = ds_val.rename_column(\"target\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824250f7",
   "metadata": {},
   "source": [
    "Le texte contenu dans les datasets n'est pas *compréhensible* en l'état par un modèle: nous devons **tokeniser** le texte. Nous devons le faire en utilisant la même méthode qui a servit à entraîner le modèle que nous utiliserons par la suite : nous choisissons [DistilRoBERTa base](https://huggingface.co/distilbert/distilroberta-base). Le choix s'est fait sur les capacités du modèle et sa taille réduite pour permettre des itérations *rapide*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55224f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilroberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "ds_train = ds_train.map(tokenize, batched=True)\n",
    "ds_val   = ds_val.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f82fc",
   "metadata": {},
   "source": [
    "Dans cette cellule nous avons réutiliser le tokenizer du modèle d'intérêt puis l'avons appliquer à la colonne contenant le texte. A présent, le dataset n'est plus composé de deux colonnes (labels et target) mais :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc70018",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4ad98",
   "metadata": {},
   "source": [
    "Avant de continuer, nous changeons le format des données en tenseur torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "ds_val.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290b844",
   "metadata": {},
   "source": [
    "La librairie transformers n'a pas de méthode `fit` comme dans scikit-learn ou Keras, mais une classe [`Trainer`](https://huggingface.co/docs/transformers/main_classes/trainer).\n",
    "Nativement, cette classe ne prend pas en compte le déséquilibre : nous allons la modifier pour le faire. On se propose d'hériter de la classe `Trainer` et de modifier uniquement la méthode `compute_loss` pour qu'elle utilise la [`CrossEntropyLoss`](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a89166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3c4c0",
   "metadata": {},
   "source": [
    "Tout au long de l'entraînement du modèle, nous voulons être capable de suivre ses performances, en plus de la valeur de la fonction de perte. Nous définissons une fonction pour répondre à cet objectif :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as sp\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, y_true = eval_pred\n",
    "    probas = sp.softmax(logits, axis=1)[:, 1]\n",
    "\n",
    "    threshold = 0.5\n",
    "    y_pred = (probas >= threshold).astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    auprc = average_precision_score(y_true, probas, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"auprc\": auprc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96a2e4",
   "metadata": {},
   "source": [
    "Pour paramétrer la classe `Trainer`, nous allons utiliser la classe [`TrainingArguments`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=[],\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6abad",
   "metadata": {},
   "source": [
    "Il est enfin temps de lancer l'entraînement !\n",
    "\n",
    "**Consigne** :\n",
    "1. Initialiser le modèle à l'aide de la classe [`AutoModelForSequenceClassification`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification), on valorisera le paramètre `num_labels` à 2 puisque nous réalisons une classification binaire.\n",
    "2. Initialiser le `WeightedTrainer` avec :\n",
    "    * Le modèle définit à l'étape précédente\n",
    "    * Comme arguments (args) le paramètrage d'entraînement défini dans la cellule précédente\n",
    "    * Les datasets d'entraînement et de test\n",
    "    * La fonction de mesure de performance\n",
    "3. Lancer l'entraînement avec la méthode `train` du `Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730681f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db1793d",
   "metadata": {},
   "source": [
    "On aimerait visualiser la performance et la distribution des réponses du modèles. Pour cela, on produit deux graphes :\n",
    "1. Graphique de distribution des probabilités du modèle sur le dataset de validation\n",
    "2. Graphique de valeurs des principales métriques (précision, recall et f1-score) en fonction du seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "def metrics_vs_threshold(y_true, y_proba, thresholds):\n",
    "    precision, recall, f1 = [], [], []\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "\n",
    "        p, r, f, _ = precision_recall_fscore_support(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"binary\",\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    return np.array(precision), np.array(recall), np.array(f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_plot(y_true, y_proba):\n",
    "    thresholds = np.linspace(0.0, 1.0, 100)\n",
    "    dataframe = pd.DataFrame({\n",
    "        \"target\": y_true,\n",
    "        \"proba\": y_proba\n",
    "    })\n",
    "\n",
    "    precision, recall, f1 = metrics_vs_threshold(\n",
    "        y_true=y_true,\n",
    "        y_proba=y_proba,\n",
    "        thresholds=thresholds\n",
    "    )\n",
    "\n",
    "    precisions, recalls, f1_scores = [], [], []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "\n",
    "    precision, recall, f1 = np.array(precisions), np.array(recalls), np.array(f1_scores)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=dataframe, x=\"proba\", hue=\"target\", common_norm=False, stat=\"probability\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.title(\"Probability distribution\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(thresholds, precision, label=\"Precision\")\n",
    "    plt.plot(thresholds, recall, label=\"Recall\")\n",
    "    plt.plot(thresholds, f1, label=\"F1-score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Threshold Optimization\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(\"Performance on validation dataset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trainer.predict(ds_val)\n",
    "probas = sp.softmax(y_pred.predictions, axis=1)\n",
    "y_proba = probas[:, 1]\n",
    "\n",
    "y_true = df_val[\"target\"].values\n",
    "make_plot(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d7883",
   "metadata": {},
   "source": [
    "Il y a deux principaux problèmes :\n",
    "1. **Overfitting** : en regardant les performances au cours de l'entraînement, on voit que la loss pour le train baisse mais pas celle de la validation\n",
    "2. **Sur-confiance** : les masses sont aux extrêmes des valeurs de probabilités, rendant difficile le choix du seuil\n",
    "\n",
    "Cela s'explique parce que nous avons ré-entraîné l'ensemble du modèle (les millions de paramètres) avec un learning rate trop aggressif. \n",
    "\n",
    "## Amélioration de la procédure\n",
    "\n",
    "Pour contrer cela, nous allons implémenter plusieurs changement:\n",
    "* Découper l'entraînement en deux parties :\n",
    "    1. Entraînement en gelant tous les poids, sauf ceux de la couche de classification sur quelques époques\n",
    "    2. Entraînement avec l'ensemble des poids sur une à deux époques, avec un learning rate faible\n",
    "* Ajouter à la fonction de perte du *label smoothing*\n",
    "* Adapter les scheduler de learning rate, quand c'est nécessaire\n",
    "* Ajouter du *weight decay*, quand c'est nécessaire\n",
    "\n",
    "Commençons !\n",
    "\n",
    "\n",
    "\n",
    "### Intégration du *label smoothing*\n",
    "\n",
    "Le *label smoothing* est une technique de régularisation introduite dans un [article](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf) améliorant l'architecture Inception. L'idée est d'adresser à la fois le surapprentissage et la sur confiance dans la prédiction.\n",
    "\n",
    "Concrétement on remplace le vecteur cible $y$ de $K$ classes par :\n",
    "\n",
    "$$\\tilde{y} = (1 - \\alpha)\\times y + \\frac{\\alpha}{K}$$ \n",
    "\n",
    "Avec $\\alpha\\in[0,1]$ issue de la loi uniforme. De cette manière on évite au logits de devenir trop grand.\n",
    "\n",
    "**Consigne** : Reprendre la classe `WeightedTrainer` pour ajouter dans la couche de [`CrossEntropyLoss`](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) le label smoothin valorisé à 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a71375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92f61fa3",
   "metadata": {},
   "source": [
    "### Premier entraînement\n",
    "\n",
    "Nous avons besoin de réinitialiser le modèle et geler l'ensemble des couches, sauf celle de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"classifier\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "n_total_parameters = sum(parameters.numel() for parameters in model.parameters())\n",
    "n_trainable_parameters = sum(parameters.numel() for parameters in model.parameters() if parameters.requires_grad)\n",
    "rate = n_trainable_parameters / n_total_parameters\n",
    "\n",
    "print(f\"{n_trainable_parameters} trainable parameters, {100 * rate:.2f}% of total model parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95be92",
   "metadata": {},
   "source": [
    "**Consigne** : Reprendre le paramètrage de `TrainingArguments` et lancer l'entraînement. Stocker les paramétrages, modèles et entraînement dans des variables différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682e048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f56e7cc",
   "metadata": {},
   "source": [
    "**Consigne** : Observer les performances métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74213f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46239161",
   "metadata": {},
   "source": [
    "### Deuxième entraînement\n",
    "\n",
    "Cette fois nous allons entraîner l'ensemble des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcce91",
   "metadata": {},
   "source": [
    "**Consigne** : Reprendre le paramètrage de `TrainingArguments` et le modifier :\n",
    "* Learning rate beaucoup plus faible\n",
    "* Nombre d'époque plus réduit\n",
    "* Ajouter du weight decay\n",
    "* Modifier le schedule du learning rate pour 'cosine'\n",
    "\n",
    "Stocker les paramétrages, modèles et entraînement dans des variables différentes. Ne pas réinitialiser en revanche le modèle : nous entraînons des poids déjà modifié.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45634c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fcb8dd5",
   "metadata": {},
   "source": [
    "On observe une optimisation du même ordre de grandeur que la première itération, mais dans une confiance plus modérée et plus de souplesse dans l'utilisation possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
